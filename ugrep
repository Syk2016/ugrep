#!/usr/bin/python3
# ugrep: find unicode characters based on their names or number.
# 	 Essentially grep for the Unicode table.

# PREREQUISITES: You must have a copy of UnicodeData.txt installed.
# On Debian GNU/Linux, this can be done by `apt install unicode-data`.
# Or, you can download it by hand from the Unicode Consortium and
# place it in `~/.local/share/unicode/UnicodeData.txt`.

# Fun things to try:

# ugrep alchemical
# ugrep ornament
# ugrep bullet
# ugrep 'vine|bud'
# ugrep vai
# ugrep heavy
# ugrep drawing
# ugrep 2300..ff

# GPL ‚â•3 (see LICENSE file)
# B9 September 2018

from re import *
from sys import argv
from pprint import pprint
from os.path import expanduser, expandvars, basename
from sys import stderr

debug=True

def usage():
    print("""\
ugrep: find unicode characters based on their names or codepoints
Usage:
    ugrep [-wcx] <character ...> | <codepoint ...> | <character name>

    	-w:	matches only whole words, e.g., ugrep -w pi
    	-c:	show each character in a string, e.g., ugrep -c "(Ôæü‚àÄÔæü)"
	-x:	show example usage

    <character> is a single character, e.g.:  ugrep ‚òô
    <codepoint> is one or more hexadecimal unicode character numbers,
		optionally prefixed by "U+" or "0x".e.g.: ugrep U+1F639.
    		Ranges are allowed with two dots: ugrep 23b0..f
    <character name> is a regular expression, see examples in ugrep --examples.
    <character string> is one or more characters. e.g., ugrep -c "( Õ°¬∞ Õú ñ Õ°¬∞)"

    Try 'ugrep --examples' to see more examples of usage.
"""
    )

def examples():
    print("""\
# You can search by character name.
    $ ugrep heart
    ‚òô	U+2619	REVERSED ROTATED FLORAL HEART BULLET
    ‚ù£	U+2763	HEAVY HEART EXCLAMATION MARK ORNAMENT
    ‚ù§	U+2764	HEAVY BLACK HEART
    [ ... examples truncated for brevity ... ]
    üòª	U+1F63B	SMILING CAT FACE WITH HEART-SHAPED EYES

# Or, you can search by pasting in a specific character.
    $ ugrep ‚úø
    ‚úø       U+273F  BLACK FLORETTE

# Or, you can search by code point.
    $ ugrep 273a
    ‚ú∫       U+273A  SIXTEEN POINTED ASTERISK

# By default, words match anywhere.
    $ ugrep clos brac			# Equivalent to "clos.*brac"
    ]       U+005D  RIGHT SQUARE BRACKET (closing square bracket)
    }       U+007D  RIGHT CURLY BRACKET (closing curly bracket)
    „Äâ      U+3009  RIGHT ANGLE BRACKET (closing angle bracket)

# Use -w to match only whole words.
    $ ugrep -w "R"			# Equivalent to "\\bR\\b"
    R	U+0052  LATIN CAPITAL LETTER R
    ‚Ñõ	U+211B  SCRIPT CAPITAL R (Script r)
    ‚Ñú	U+211C  BLACK-LETTER CAPITAL R (Black-letter r)
    ‚Ñù	U+211D  DOUBLE-STRUCK CAPITAL R (Double-struck r)

# Use -c to display info for each character in a string.
    $ ugrep -c "·ïï( ·êõ )·ïó"
    ·ïï	U+1555	CANADIAN SYLLABICS FI
    (	U+0028	LEFT PARENTHESIS (opening parenthesis)
    ·êõ	U+141B	CANADIAN SYLLABICS NASKAPI WAA
    )	U+0029	RIGHT PARENTHESIS (closing parenthesis)
    ·ïó	U+1557	CANADIAN SYLLABICS FO

# ugrep finds aliases (in parens)
    $ ugrep backslash
    \	U+005C	REVERSE SOLIDUS (backslash)

# Regex ^ and $ work, mostly
    $ ugrep ^x
    ‚äª	U+22BB	XOR
    ‚åß	U+2327	X IN A RECTANGLE BOX (clear key)

# Show every single Unicode character!
    $ ugrep 0..10FFFF  |  less"""
    )

# Main
def main():
    global argv

    if len(argv) == 1:
        usage()
        exit(1)

    if argv[1]=='-h' or argv[1]=='--help':
        usage()
        exit(0)

    if argv[1]=='-x' or argv[1]=='--examples' or argv[1]=='--example':
        examples()
        exit(0)

    if argv[1]=='-w':
        argv=argv[1:]
        for i in range(1,len(argv)):
            argv[i]="\\b"+argv[i]+"\\b"
        debugprint(argv)

    # Load the Unicode Data into the global ucd variable.
    loaducd()
    # Same for NamesList.txt file into nameslist variable.
    loadnameslist()

    # Is it -c followed by a string of characters?
    if argv[1]=='-c':
        # Look up each character in the string.
        argv=argv[1:]
        for i in range(1,len(argv)):
            for j in range(0,len(argv[i])):
                showonecharacter( hex(ord(argv[i][j])) )
            if (i<len(argv)-1): print("")
        exit(0)

    # Is it a single character? Then only show that one character.
    if len(argv[1])==1:
        showonecharacter( hex(ord(argv[1])) )
        exit(0)

    # Do brace expansion on argv if our system doesn't have it.
    braceexpansion()

    # Is first arg a hexadecimal number? E.g., 26A0, 0xdeadbeef, U+FACE
    # Then *also* look up that code point.
    if match(r"(?i)^(U\+?|0x)?[0-9A-F]+$", argv[1]):
        # Loop to allow people to do things like "ugrep 23b{0..9}"
        for arg in argv[1:]:
            if match(r"(?i)^(U\+?|0x)?[0-9A-F]+$", arg):
                showonecharacter(arg)
            else:
                break

    # Now, look up the entire argv[] as a character name or alias.
    s=makeregexcharname()
    printmatches(s)

    # Finally, look up argv[] as an entry in the NamesList.txt.
    # For examples, `ugrep eggplant` should return U+1F346 AUBERGINE.
    # (Argh. This would be so much easier in Awk.)
    s=makeregexnameslist()
    printnameslistmatches(s)


def showonecharacter(c):
    s=makeregexcodepoint(c)
    compileit(s)
    printmatches(s)


def compileit(s):
    "Compile the regular expresion in s, or die trying."
    global ucd, argv

    if debug:
        debugprint(s)
        m=search(s,ucd)
        if not m: debugprint("Uncompiled, definitely not in ucd")

    try:
        s=compile(s)
    except error as e:
        err("Error parsing regex: '%s'" % ".*".join(argv[1:]))
        err(e)
        exit(3)



def isprint(c):
    # Given a category 'c', return True if it is printable.
    # We presume the only non-printable category is 'C' (control).
    # However, technically, much of category 'Z' (spaces) is non-printable.

    # Side note: Python is silly and regex clauses that match an empty
    # string are set to None instead of ''. That's why we doublecheck
    # that category is not None.
    return c and not c.startswith('C')

def iscombining(c):
    # Given a category 'c', return True if it is a combining character.
    # We presume all combining characters are in category 'M' and vice-versa.
    if debug:
        debugprint ("Category is <" + str(c) + ">")

    return c and c.startswith('M')

def printmatches(s):
    category=""
    for m in finditer(s, ucd):
        if m:
            g=m.groupdict()
            debugprint(g)
            if g["hex"] == None: g["hex"]=g["hextwo"]
            if g["name"] == None: g["name"]=g["desctwo"]
            category = g["category"] if g["category"] else g["categorytwo"]
            if g["alias"] == None: g["alias"]=g["aliastwo"]
            c=chr(int(g["hex"], 16))
            if not isprint(category): c="\ufffd" # "Replacement Character"
            if iscombining(category): print('\u25cc', end='') # "Dotted circle"
            print(c, end='\t')
            print ("U+" + g["hex"], end='\t')
            print(g["name"], end='')
            if (len(g["alias"]) and isdifferent(g["name"], g["alias"])):
                print (" (" + g["alias"].lower() + ")", end='')
            print()

def printnameslistmatches(s):
    for m in finditer(s, nameslist):
        if m:
            g=m.groupdict()
            debugprint(g)
            c=chr(int(g["hex"], 16))
            if not isprint(category): c="\ufffd" # "Replacement Character"
            if iscombining(category): print('\u25cc', end='') # "Dotted circle"
            print(c, end='\t')
            print ("U+" + g["hex"], end='\t')
            print(g["name"], end='')
            print()

def isdifferent(a, b):
    """Given two strings A & B, determine if B is different enough from A
       that we don't need to print it as well. "Enough" means "adds
       significant new information". For example, the following would
       return False:

       "LATIN CAPITAL LETTER A WITH GRAVE", "LATIN CAPITAL LETTER A GRAVE"

       Note that order matters. For example,

       "BROKEN BAR", "BROKEN VERTICAL BAR" 	Should return True
       "BROKEN VERTICAL BAR", "BROKEN BAR" 	Should return False
    """
    a=a.upper()
    b=b.upper()

    if a == b:
        return False
    if a == b.replace(" DIGIT ", " "):
        return False
    if a == b.replace("FORMS ", "BOX DRAWINGS "):
        return False
    if a == b.replace("GRAPHIC ", "SYMBOL "):
        return False
    if a == b.replace("GLYPH ", "PRESENTATION FORM "):
        return False
    if a == b.replace("CENTER", "CENTRE"):
        return False
    if a == b.replace("CENTERED", "CENTRED"):
        return False
    if a == b.replace("SQUARED ", "SQUARE "):
        return False

    b=b.replace(" ", ".*")
    try:
        m=search(b, a)
        if m:
            return False
        else:
            return True
    except:
        # regex should never fail, but if it does, we don't care.
        return True


    # if a.replace("WARDS ", " ") == b:
    #     return False
    # if a.replace("S ", " ") == b:
    #     return False
    # if a.rstrip("S") == b:
    #     return False

    return True

def loaducd():
    "Find the UnicodeData.txt file and load it up into ucd global variable."

    global ucd
    ucd=None
    ucdplaces=( "/usr/local/share/unicode/UnicodeData.txt",
                "/usr/share/unicode/UnicodeData.txt",
                "~/.local/share/unicode/UnicodeData.txt",
                "UnicodeData.txt" )
    for f in ucdplaces:
        f=expanduser(expandvars(f)) 		# Python's open() is silly
        try:
            ucd=open(f).read()
            debugprint("Found data file at " + f)
        except:
            continue

    # Sanity check: did we find the UnicodeData.txt file?
    if ucd == None:
        eprint("""\
    Could not find UnicodeData.txt in:

%s
    On most GNU/Linux systems your package manager can install it easily.
    For example:  apt install unicode-data.

    Alternately, you can grab it via wget like so:

        mkdir -p ~/.local/share/unicode
	cd ~/.local/share/unicode
        wget ftp://ftp.unicode.org/Public/UNIDATA/UnicodeData.txt
""" %
               ("".join(["    " + s + "\n" for s in ucdplaces])))
        exit(2)

    if debug:
        debugprint("Number of Unicode chars: %d" % len(ucd.splitlines()))

    return ucd

def loadnameslist():
    "Find the nameslist.txt file and load it up into nameslist global variable."

    global nameslist
    nameslist=None
    nlplaces=( "/usr/local/share/unicode/NamesList.txt",
                "/usr/share/unicode/NamesList.txt",
                "~/.local/share/unicode/NamesList.txt",
                "NamesList.txt" )
    for f in nlplaces:
        f=expanduser(expandvars(f)) 		# Python's open() is silly
        try:
            nameslist=open(f).read()
            debugprint("Found nameslist file at " + f)
        except:
            continue

    # Sanity check: did we find the NamesList.txt file?
    if nameslist == None:
        eprint("""\
    Could not find NamesList.txt in:

%s
    On most GNU/Linux systems your package manager can install it easily.
    For example:  apt install unicode-data.

    Alternately, you can grab it via wget like so:

        mkdir -p ~/.local/share/unicode
	cd ~/.local/share/unicode
        wget ftp://ftp.unicode.org/Public/UNIDATA/NamesList.txt
""" %
               ("".join(["    " + s + "\n" for s in nlplaces])))
        # XXX Todo: issue a warning but not fail if missing NamesList.txt
        exit(2)

    return nameslist


def makeregexcharname():
    "Create a regular expression to search for a character name"

    # Format of ucd: each character is on a separate line.
    # Each line is fifteen columns separated by semicolons.
    # We only care about columns 1, 2, 3 and 11
    #      1: Code value
    #      2: Character name
    #      3: General category
    #     11: ISO 10646 comment field (usually an alias)
    #
    # For example:
    #     002F;SOLIDUS;Po;0;CS;;;;;N;SLASH;;;;
    #
    # See Tech Report 44 for more details.
    #
    # XXX Todo: maybe look up in table of confusable entities. (NamesList.txt)

    # combine and quote the command line arguments so we can use them in
    # verbose regex. Also, allow the user to use ^ and $, just like in awk
    # to refer to the beginning and end of the field instead of line.
    global argv
    argv=["("+x+")" for x in argv]    # wrap in parens to fix | (alternation)
    args=".*".join(argv[1:])          # search terms can have junk between
    args=sub(r"(\s)", r"\\\1", args)  # quote whitespace for verbose regex
    args=sub(r"^\(\^", r"(?<=;)(", args) # ^ matches semicolon before field
    args=sub(r"\$\)$", r"(?=;))", args)  # $ matches semicolon after field

    # s is a search regex for field 2 (name) based on the command line arguments
    s=r"""^
        (?P<hex>[^;]*);             # first field is hexadecimal codepoint
        (?P<name>[^;]*"""+args+"""[^;]*); # field 2 (charactername) matches?
        (?P<category>[^;]*);        # third field is general category
        ([^;]*;){7}                 # skip next 7 fields
        (?P<alias>[^;]*)            # field 11 is comment/alias
        (;[^;]*){4}$                # line ends with four more fields
    """

    # r is a search regex for field 11 (alias)
    r=r"""^
        (?P<hextwo>[^;]*);            # first field is hexadecimal codepoint
        (?P<desctwo>[^;]*);           # second field is charactername
        (?P<categorytwo>[^;]*);       # third field is general category
        ([^;]*;){7}                   # skip next 7 fields
        (?P<aliastwo>[^;]*("""+args+""")[^;]*) # field 11 (alias) matches?
        (;[^;]*){4}$                  # line ends with four more fields
    """

    s=s+"|"+r                   # Search for either name or alias
    s="(?mix)"+s                # multiline, case insensitive, verbose

    debugprint("Complete search regex is " + s)

    return s

def makeregexnameslist():
    "Create a regular expression to search for an alias in NamesList.txt"

    # Format of NamesList.txt is multiple lines. (Wish I had awk for this).
    # Note: ‚á•‚Éû means TAB character.
    #
    # Each character on its own line :
    # 	hex‚á•‚Éûcharname		      | 1F346	AUBERGINE
    #				      |
    # Followed by zero or more lines: |
    # Synonym:			      |
    #      ‚á•‚Éû= text[, text...]         |		= eggplant
    # Commentary on standards	      |
    #      @+‚á•‚Éû* text		      |	@+	* see ISO 69835 for details
    # Commentary:		      |
    #      ‚á•‚Éû* text		      |		* most commonly depicts a penis
    # Cross reference:		      |
    #      ‚á•‚Éûx (text - hex)	      |		x (hand with middle finger extended - 1F595)
    # Variation:		      |
    #      ‚á•‚Éû# hex... text	      |		# 2642 male sign
    #      ‚á•‚Éû# <how> hex... 	      |		# <noBreak> 1F34C
    # Canonical equivalent:	      |
    #      ‚á•‚Éû: hex text		      | 00C0	LATIN CAPITAL LETTER A WITH GRAVE
    #				      |		: 0041 0300
    # Alternate presentation form:    |
    #      ‚á•‚Éû~ hex... text	      | FF1F    FULLWIDTH QUESTION MARK
    #				      |	        ~ FF1F FE00 corner-justified form
    #				      |	        ~ FF1F FE01 centered form
    #				      |	        # <wide> 003F
    #				      |
    # Range: @@‚á•‚Éûstart‚á•‚Éûdescription‚á•‚Éûend | @@	1F650	Ornamental Dingbats	1F67F
    # Section dividers: @‚á•‚Éû‚á•‚Éûtext	      | @		Fleurons
    # Section comments: @+‚á•‚Éû‚á•‚Éûtext      | @+		Fleurons are leaf or floral-shaped ornaments used for text decoration.
    #				      | 1F650	NORTH WEST POINTING LEAF
    #				      | 1F651	SOUTH WEST POINTING LEAF


    # Examples of regulard commentary  and standards commentary:
    # 1E37    LATIN SMALL LETTER L WITH DOT BELOW
    #         * Indic transliteration
    #         : 006C 0323
    # @+      * see ISO 15919 on the use of dot below versus ring below in Indic transliteration
    #         x (combining ring below - 0325)
    # 2301    ELECTRIC ARROW
    # @+      * from ISO 2047
    #         * symbol for End of Transmission

    # Example of commentary on sections (indented by two tabs):
    # @               Ceilings and floors
    # @+              These characters are tall and narrow mathematical delimiters, in contrast to the quine corners or half brackets. They are also distinct from CJK corner brackets, which are wide quotation marks.
    

    # Variation Examples:
    # 2007    FIGURE SPACE
    # 	      * space equal to tabular width of a font
    # 	      * this is equivalent to the digit width of fonts with fixed-width digits
    # 	      # <noBreak> 0020
    # 200A    HAIR SPACE
    #         * thinner than a thin space
    #         * in traditional typography, the thinnest space available
    #         # 0020 space
    # 2026    HORIZONTAL ELLIPSIS
    #         = three dot leader
    #         x (vertical ellipsis - 22EE)
    #         x (presentation form for vertical horizontal ellipsis - FE19)
    #         # 002E 002E 002E
    # 1FBF0   SEGMENTED DIGIT ZERO
    #         # <font> 0030 digit zero

    # Canonical equivalent example:
    # 1D164   MUSICAL SYMBOL ONE HUNDRED TWENTY-EIGHTH NOTE
    #         = semihemidemisemiquaver, quasihemidemisemiquaver
    #         : 1D15F 1D172

    # Alternate form example:
    # 2205    EMPTY SET
    #         = null set
    #         * used in linguistics to indicate a null morpheme or phonological "zero"
    #         x (latin capital letter o with stroke - 00D8)
    #         x (diameter sign - 2300)
    #         ~ 2205 FE00 zero with long diagonal stroke overlay form

    # Extended attribute lines attached to section comment:
    # @               Accidentals
    # @+              The most common accidentals are encoded in the Miscellaneous Symbols block.
    #                 x (music flat sign - 266D)
    #                 x (music natural sign - 266E)
    #                 x (music sharp sign - 266F)


    # What does @~ mean? It is always followed by either "‚á•‚Éû!" or
    # "‚á•‚ÉûStandardized Variation Sequences"
    # 
    # 007F    <control>
    #         = DELETE
    # @~      !
    # @@      0080    C1 Controls and Latin-1 Supplement (Latin-1 Supplement) 00FF
    # @               C1 controls
    # @+              Alias names are those for ISO/IEC 6429:1992.
    # 0080    <control>
    


    # All lines that start with @ have one of these prefixes:
       # @‚á•‚Éû‚á•‚Éû			# Section title
       # @+‚á•‚Éû‚á•‚Éû			# Section comment
       # @+‚á•‚Éû*			# Standards comment
       # @@‚á•‚Éû			# Range Title
       # @@+			# [The space intentionally left blank]
       # @~‚á•‚Éû			# "Standardized Variation Sequences"(?)
       # @@@			# Unicode Standard folderol

    # Ignoring the first 12 lines which are just Unicode prologue,
    # all lines that start with ‚á•‚Éû (TAB) have one of these prefixes
       # ‚á•‚Éû*‚ê†			# Commentary
       # ‚á•‚Éû#‚ê†			# Variant
       # ‚á•‚Éûx‚ê†			# Crossreference
       # ‚á•‚Éû=‚ê†			# Synonym
       # ‚á•‚Éû:‚ê†			# Canonical equivalent
       # ‚á•‚Éû~‚ê†			# Alternate presentation form
       # ‚á•‚Éû‚á•‚Éûx‚ê†			# Xref in section comment
       # ‚á•‚Éû%‚ê†			# Unicode commentary
    # (Note that ‚ê† represents the SPACE character):


    # Example of Unicode commentary:
    # FEFF    ZERO WIDTH NO-BREAK SPACE
    #         % BYTE ORDER MARK
    #         = BOM, ZWNBSP
    # 0EA3    LAO LETTER LO LING
    #         % LAO LETTER RO
    #         = ro rot
    #         * name is a mistake, lo ling is the mnemonic for 0EA5
    # 0EA5    LAO LETTER LO LOOT
    #         % LAO LETTER LO
    #         = lo ling
    #         * name is a mistake, lo loot is the mnemonic for 0EA3

    # Three entries have abberant use of semicolons instead of commas:
    # 1F70A   ALCHEMICAL SYMBOL FOR VINEGAR
    #         = crucible; acid; distill; atrament; vitriol; red sulfur; borax; wine; alkali salt; mercurius vivus, quick silver
    #         x (cross of jerusalem - 2629)
    # 0598    HEBREW ACCENT ZARQA
    #         = tsinorit, zinorit; tsinor, zinor
    #         * This character is to be used when Zarqa or Tsinor are placed above, and also for Tsinorit.
    #         x (hebrew accent zinor - 05AE)
    # 05AE    HEBREW ACCENT ZINOR
    #         = tsinor; zarqa
    #         * This character is to be used when Zarqa or Tsinor are placed above left.
    #         x (hebrew accent zarqa - 0598)

    # Maybe should treat semicolons as commas, but that would break this one entry:
    # 29DC    INCOMPLETE INFINITY
    #         = ISOtech entity &iinfin;
    #         x (infinity - 221E)

    # File begins with a header discouraging machine-reading, but
    # since this data is nowhere else, we are forced to parse it:
    #
    # ; charset=UTF-8
    # @@@     The Unicode Standard 13.0.0
    # @@@+    U13M200203.lst
    #         Unicode 13.0.0 final names list.
    #         This file is semi-automatically derived from UnicodeData.txt and
    #         a set of manually created annotations using a script to select
    #         or suppress information from the data file. The rules used
    #         for this process are aimed at readability for the human reader,
    #         at the expense of some details; therefore, this file should not
    #         be parsed for machine-readable information.
    # @+              ¬© 2020 Unicode¬Æ, Inc.
    #         For terms of use, see http://www.unicode.org/terms_of_use.html




    # EXAMPLE ENTRIES
    #
    # 2052    COMMERCIAL MINUS SIGN
    #         = abz√ºglich (German), med avdrag av (Swedish), piska (Swedish, "whip")
    #         * a common glyph variant and fallback representation looks like ./.
    #         * may also be used as a dingbat to indicate correctness
    #         * used in Finno-Ugric Phonetic Alphabet to indicate a related borrowed form with different sound
    #         x (percent sign - 0025)
    #         x (arabic percent sign - 066A)
    #         x (division sign - 00F7)

    # 1F374	FORK AND KNIFE
    # 		= restaurant, meal
    # 		* glyph may show a fork and spoon
    # 		* glyph may show a crossed fork and knife
    # 		x (fork and knife with plate - 1F37D)
    # 		x (spoon - 1F944)

    # 1F943	TUMBLER GLASS
    #         	= whisky
    #         	* typically shown with ice
    #         	x (cocktail glass - 1F378)

    # 1FBB2	LEFT HALF RUNNING MAN
    #         	* paired with 1FBB3, faces to the right
    #         	* the Apple II documentation refers to these characters as "Running Man"
    #         	x (runner - 1F3C3)
    ######################################################################
    
    # combine and quote the command line arguments so we can use them in
    # verbose regex. 
    global argv
    argv=["("+x+")" for x in argv]    # wrap in parens to fix | (alternation)
    args=".*".join(argv[1:])          # search terms can have junk between
    args=sub(r"(\s)", r"\\\1", args)  # quote whitespace for verbose regex

XXX buggy. does not do multiline right yet. There has to be a better way.

    # s is a search regex for field 2 (name) based on the command line arguments
    s=r"""^	                    # Head anchor 
        (?P<hex>[0-9A-F]+)\t;       # first field is hexadecimal codepoint
        (?P<name>.*$);              # second field is character name
        (^(\t|@\+))+; 	    	    # at least one subsequent line that starts with a TAB or @+
        ("""+args+"""); 	    # command line args 
    """
    s="(?mix)"+s                # multiline, case insensitive, verbose

    debugprint("Complete search regex is " + s)

    return s

def makeregexcodepoint(cp):
    "Make a regular expression to search for a hexadecimal codepoint"

    # User specified a codepoint, e.g., "U+23fb"

    # Normalize whatever they put in to "23FB"
    cp=cp.lstrip("Uu+0Xx").upper().zfill(4)

    # s is a search regex for field 1 (hexadecimal)
    s=r"""^
        (?P<hex>"""+cp+""");		#first field is hex codepoint
        (?P<name>[^;]*);		# second field is charactername
        (?P<category>[^;]*);		# third field is category
        ([^;]*;){7}			# skip next 7 fields
        (?P<alias>[^;]*)            	# field 11 is comment/alias
    """
    s="(?mix)"+s                     # multiline, case insensitive, verbose
    return(s)



def braceexpansion():
    """Look for ranges "{a..z}" in argv[] and expand by inserting new elements.

    {0..7} 	-->	0 1 2 3 4 5 6 7
    abc{0..7} 	--> 	abc0 abc1 abc2 abc3 abc4 abc5 abc6 abc7

    This is mostly useful for people who do not run a modern UNIX
    shell, like GNU Bash that expands braces on the command line.

    It also fills in the gap until shells understand hexadecimal
    ranges. For example, the following is ignored by bash-4.4, but we
    want to accept it in ugrep.

    23b{8..f}	-->	23b8 23b9 23ba 23bb 23bc 23bd 23be 23bf

    Notes:

    * In Bash, if start or end begin with a "0", then it zfills to
      that width. For this program, the 0 is optional as it always
      uses the largest width of the two ends E.g., 23{0..ff} -> 2300, 2301,...
    * Does not handle nested braces nor alternation with a comma.
    * Should check for invalid ranges and ignore them instead of barfing.
    * Checks for and ignores prefix of U+ or 0x

    * Presumes both arguments are hexadecimal, this makes things weird where
      {01..10} is expanded by Bash to ten numbers, but
      {01..0f} is expanded by this program to fifteen!

    * Because of that inconsistency, maybe this isn't such a good idea.
      Perhaps we should make people have to prefix hex with U+ or 0x?

    """

    global argv
    s=r"""(?mix)
	  (?P<prefix>[^{]*)
	  {?                   # Literal open curly brace (optional)
	  (U\+?|0?x)?
    	  (?P<start>.*)
	  \.\.                 # Literal two periods. MANDATORY.
	  (U\+?|0?x)?
	  (?P<end>.*)
	  }?                   # Literal close curly brace (optional)
	  (?P<suffix>[^}]*)
    """
    s=compile(s)
    newargv=[argv[0]]

    for arg in argv[1:]:
        m=search(s, arg)
        if not m:
            newargv.append(arg)
        else:
            debugprint("Doing brace expansion on " + arg)
            g=m.groupdict()
            prefix=g["prefix"]
            start=g["start"].strip("{}") # Python doesn't do lazy regexps?
            end=g["end"].strip("{}")     # So, we kludge this way.

            if start == "":
                # They left off the braces: 2390..f instead of 239{0..f}
                start=prefix
                end=prefix[:-len(end)]+end
                prefix=""

            debugprint("Found range from " + start + " to " + end)
            z=max(len(start), len(end))
            start=int(start, 16)
            end=int(end, 16)

            for i in range(start, end+1):
                hexits=hex(i)[2:].zfill(z)
                newargv.append( prefix + hexits + g["suffix"] )

    argv=newargv
    return(0)


def eprint(*args, **kwargs):
    "Print to stderr"
    print(*args, file=stderr, **kwargs)

def err(*args, **kwargs):
    "Print to stderr with program name prefixed"
    eprint(basename(argv[0]) + ": ", end='')
    eprint(*args, **kwargs)

def debugprint(*args, **kwargs):
    "If debug var is True, print to stderr with progname prefix"
    if (debug):
        err(*args, **kwargs)



### Run the main routine
try:
    main()
except BrokenPipeError:
    # Ignore non-error errors. For example: 'ugrep -w pi | head'
    True


# Implementation notes:

# This is a rewrite of b9's AWK ugrep in Python. While AWK makes a lot
# more sense for what this program does (comparing fields based on
# regexps), a rewrite was necessary because GNU awk, while plenty
# powerful, uses \y for word edges instead of \b and that was bugging
# me. Gawk does this for backwards compatibility with historic AWK,
# which is all well and good, but gawk has no way to disable it for
# new scripts.
#
# Switching to Python did have the benefit of allowing more powerful
# Perl-like regexes (not that anyone has requested that).
#
# One downside is that I needed a huge hairy regex to simply search
# only in a certain field of each line. Maybe there's some Pythonic
# way to do it, but it's not obvious. Perhaps a 2D array?
#
# Also, I took for granted that awk let me use ^ and $ to search for
# the beginning and ending of fields instead of lines. I tried to
# reimplement that in Python, but it's not quite right as it only
# checks the first and last character. For example, ugrep "^x" works,
# but ugrep "(^x)" does not.


# Note: I do not use Python's `unicodedata` module because it is
# insufficient. It allows one to search by character name only if the
# precise name: `unicodedata.lookup("ROTATED HEAVY BLACK HEART BULLET")`.
